{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "fp = \"D:\\\\DBC\\\\Dataset\\\\images\\\\Images\"\n",
    "print(os.listdir(fp))\n",
    "dog_classes = os.listdir(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds = [breed.split('-',1)[1] for breed in dog_classes]\n",
    "print(breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "fullpaths = [\"D:\\\\DBC\\\\Dataset\\\\images\\\\Images\\\\{}\".format(dog_class) for dog_class in dog_classes]\n",
    "\n",
    "for counter, fullpath in enumerate(fullpaths):\n",
    "    for imgname in os.listdir(fullpath):\n",
    "        x.append([fullpath + '\\\\' + imgname])\n",
    "        y.append(breeds[counter])\n",
    "        \n",
    "print(x[:10],'\\n')\n",
    "print(y[:10],'\\n')\n",
    "\n",
    "x = list(chain.from_iterable(x))\n",
    "print(x[:10],'\\n')\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "combined = list(zip(x,y))\n",
    "print(combined[:10],'\\n')\n",
    "random.shuffle(combined)\n",
    "print(combined[:10],'\\n')\n",
    "x[:],y[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.image import imread\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "\n",
    "for counter, i in enumerate(random.sample(range(0, len(x)),9)):\n",
    "    plt.subplot(3,3 ,counter + 1)\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    filename = x[i]\n",
    "    image = imread(filename)\n",
    "    plt.imshow(image)\n",
    "    plt.title(y[i],fontsize=12)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[:2300]\n",
    "y = y[:2300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(y,open('y.dat','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pickle.load(open('y.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y_ohe = to_categorical(le.transform(y),len(breeds))\n",
    "print(y_ohe.shape)\n",
    "\n",
    "y_ohe = np.array(y_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array,load_img\n",
    "\n",
    "img_data = np.array([img_to_array(load_img(img, target_size=(299,299))) for img in x])\n",
    "print(img_data.shape)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(img_data,y_ohe,test_size = 0.2,random_state = 2)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.2,random_state = 2)\n",
    "\n",
    "print(\"Training dataset size: \",x_train.shape)\n",
    "print(\"Validation dataset size: \",x_val.shape)\n",
    "print(\"Testing dataset size: \",x_test.shape)\n",
    "print(\"Training label size: \",y_train.shape)\n",
    "print(\"Validation label size: \",y_val.shape)\n",
    "print(\"Testing label size: \",y_test.shape)\n",
    "\n",
    "import gc\n",
    "del img_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                  rotation_range=30,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train,y_train,shuffle=False,batch_size = batch_size,seed =1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_generator = val_datagen.flow(x_val,y_val,shuffle=False,batch_size = batch_size,seed =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 2\n",
    "dog_generator = train_datagen.flow(x_train[img_id:img_id+1],y_train[img_id:img_id+1]\n",
    "                                     ,shuffle=False,batch_size = batch_size,seed =1)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "dogs = [next(dog_generator) for i in range(0,5)]\n",
    "for counter, dog in enumerate(dogs):\n",
    "    plt.subplot(1,5,counter+1)\n",
    "    plt.imshow(dog[0][0])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import GlobalAveragePooling2D,Dense,Flatten,Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet',include_top=False,input_shape=(299,299,3))\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(len(breeds),activation='softmax'))\n",
    "\n",
    "print(\"Number of trainable weights before freezing the base layer: \",len(model.trainable_weights))\n",
    "model.layers[0].trainable = False\n",
    "print(\"Number of trainable weights after freezing the base layer: \",len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = adam_v2.Adam(learning_rate=0.0001)\n",
    "model.compile(o,loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps_per_epoch = x_train.shape[0] // batch_size\n",
    "val_steps_per_epoch = x_val.shape[0] // batch_size\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit_generator(train_generator,steps_per_epoch=train_steps_per_epoch,validation_data=val_generator,\n",
    "                             validation_steps=val_steps_per_epoch,epochs = epochs,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1,ax2) = plt.subplots(1, 2,figsize=(12,4))\n",
    "t = f.suptitle('Transfer Learning Performance',fontsize = 12)\n",
    "f.subplots_adjust(top=0.85,wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1,epochs+1))\n",
    "ax1.plot(epoch_list,history.history['accuracy'],label='Train Accuracy')\n",
    "ax1.plot(epoch_list,history.history['val_accuracy'],label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0,epochs+1,5))\n",
    "ax1.set_ylabel('Accuracy value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc = 'best')\n",
    "\n",
    "ax2.plot(epoch_list,history.history['loss'],label='Train Loss')\n",
    "ax2.plot(epoch_list,history.history['val_loss'],label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0,epochs+1,5))\n",
    "ax2.set_ylabel('Loss value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = x_test/255.\n",
    "test_predictions = model.predict(x_test1)\n",
    "\n",
    "predictions = le.classes_[np.argmax(test_predictions,axis=1)]\n",
    "target_labels = le.classes_[np.argmax(y_test,axis=1)]\n",
    "\n",
    "predict_df = pd.DataFrame({'Target_Labels':target_labels, 'Predictions':predictions})\n",
    "predict_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = (target_labels == predictions)\n",
    "accuracy = correct.sum() / correct.size\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(target_labels,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particular Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = x_test/255.\n",
    "test_predictions = model.predict(x_test1)\n",
    "\n",
    "predictions = le.classes_[np.argmax(test_predictions,axis=1)]\n",
    "target_labels = le.classes_[np.argmax(y_test,axis=1)]\n",
    "\n",
    "predict_df = pd.DataFrame({'Target_Labels':target_labels, 'Predictions':predictions})\n",
    "predict_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = (target_labels == predictions)\n",
    "accuracy = correct.sum() / correct.size\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(target_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    img = load_img(filename, color_mode = \"rgb\", target_size=(299, 299, 3))\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape(1, 299, 299, 3)\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "def output(image):\n",
    "    img = load_image(image)\n",
    "    test_predictions = model.predict(img)\n",
    "    print(test_predictions)\n",
    "    predictions = le.classes_[np.argmax(test_predictions,axis=1)]\n",
    "    print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    " \n",
    "img = io.imread(\"Shih Tzu.jpg\")\n",
    "io.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output('Shih Tzu.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(\"American_Staffordshire_terrier.jpg\")\n",
    "io.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output('American_Staffordshire_terrier.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(\"labrador retriever.jpg\")\n",
    "io.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output(\"labrador retriever.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from itertools import chain\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from flask import Flask, redirect, url_for, request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from keras.models import load_model\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "y = pickle.load(open('y.dat','rb'))\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "UPLOAD_FOLDER = './uploads'\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "\n",
    "MODEL_PATH ='final_model.h5'\n",
    "\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "\n",
    "def model_predict(img_path, model):\n",
    "    \n",
    "    img = load_img(img_path, color_mode = \"rgb\", target_size=(299, 299, 3))\n",
    "    x = img_to_array(img)\n",
    "    x = x/255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    test_predictions = model.predict(x)\n",
    "    predictions = le.classes_[np.argmax(test_predictions,axis=1)]\n",
    "    return predictions[0]\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=['GET', 'POST'])\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        if 'file1' not in request.files:\n",
    "            return 'there is no file1 in form!'\n",
    "        file1 = request.files['file1']\n",
    "        path = os.path.join(app.config['UPLOAD_FOLDER'], file1.filename)\n",
    "        file1.save(path)\n",
    "        return model_predict(path,model)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
